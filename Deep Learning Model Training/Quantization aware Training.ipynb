{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf4f9d6",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49471053",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.6.0\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#Check TensorFlow version:\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorFlow Version: \u001b[39m\u001b[38;5;124m\"\u001b[39m, tf\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfmot\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#Check if #### Process DatasetGPU is being used:\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\__init__.py:86\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# To ensure users only access the expected public API, the API structure is\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# created in the `api` directory. Import all api modules.\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\api\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Import API modules for Tensorflow Model Optimization.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\api\\clustering\\__init__.py:16\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Module containing code for clustering.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\api\\clustering\\keras\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-bad-import-order\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_scope\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_weights\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m strip_clustering\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\clustering\\keras\\cluster.py:22\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_config\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cluster_wrapper\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[0;32m     25\u001b[0m k \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mbackend\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\clustering\\keras\\cluster_wrapper.py:24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clusterable_layer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_centroids\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_model_optimization\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clustering_registry\n\u001b[0;32m     26\u001b[0m attrgetter \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mattrgetter  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[0;32m     27\u001b[0m keras \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\clustering\\keras\\clustering_registry.py:57\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ans\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ClusteringAlgorithm\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mClusteringRegistry\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m     58\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Registry responsible for built-in keras layers.\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m   \u001b[38;5;66;03m# The keys represent built-in keras layers and the values represent the\u001b[39;00m\n\u001b[0;32m     61\u001b[0m   \u001b[38;5;66;03m# the variables within the layers which hold the kernel weights. This\u001b[39;00m\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;66;03m# allows the wrapper to access and modify the weights.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_model_optimization\\python\\core\\clustering\\keras\\clustering_registry.py:85\u001b[0m, in \u001b[0;36mClusteringRegistry\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# The keys represent built-in keras layers and the values represent the\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# the variables within the layers which hold the kernel weights. This\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# allows the wrapper to access and modify the weights.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m _LAYERS_WEIGHTS_MAP \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     64\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv1D: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     65\u001b[0m     layers\u001b[38;5;241m.\u001b[39mConv1DTranspose: [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLayerNormalization: [],\n\u001b[0;32m     80\u001b[0m }\n\u001b[0;32m     82\u001b[0m _SUPPORTED_RNN_CELLS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m({\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;66;03m# Sometimes v2 RNN will wrap some v1 RNN cells and we need\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# to consider this\u001b[39;00m\n\u001b[1;32m---> 85\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mv1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[38;5;241m.\u001b[39mGRUCell,\n\u001b[0;32m     86\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mGRUCell,\n\u001b[0;32m     87\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTMCell,\n\u001b[0;32m     88\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mLSTMCell,\n\u001b[0;32m     89\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mSimpleRNNCell,\n\u001b[0;32m     90\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mSimpleRNNCell,\n\u001b[0;32m     91\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mStackedRNNCells,\n\u001b[0;32m     92\u001b[0m     tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv2\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mStackedRNNCells,\n\u001b[0;32m     93\u001b[0m })\n\u001b[0;32m     95\u001b[0m _SUPPORTED_RNN_LAYERS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfrozenset\u001b[39m([\n\u001b[0;32m     96\u001b[0m     layers\u001b[38;5;241m.\u001b[39mGRU,\n\u001b[0;32m     97\u001b[0m     layers\u001b[38;5;241m.\u001b[39mLSTM,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m     layers\u001b[38;5;241m.\u001b[39mBidirectional,\n\u001b[0;32m    101\u001b[0m ])\n\u001b[0;32m    103\u001b[0m _SUPPORTED_MHA_LAYERS \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    104\u001b[0m     tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMultiHeadAttention,\n\u001b[0;32m    105\u001b[0m }\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m---> 62\u001b[0m   module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_module_globals[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_local_name] \u001b[38;5;241m=\u001b[39m module\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Lambda, concatenate, Add\n",
    "from tensorflow.keras.layers import UpSampling2D, SeparableConv2D, Input, Concatenate, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from skimage.metrics import structural_similarity\n",
    "from tensorflow import keras\n",
    "#Check TensorFlow version:\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "import tensorflow_model_optimization as tfmot\n",
    "#Check if #### Process DatasetGPU is being used:\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d0a708",
   "metadata": {},
   "source": [
    "#### Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3130375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  25426\n",
      "Validation data:  3178\n",
      "Testing data:  3178\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "path_read_scene_and_flares = \"/PATH/Merged_images/\"\n",
    "path_read_scenes = \"/PATH/Merged_images_saturated/\"\n",
    "EPOCHS = 300\n",
    "BATCH = 12\n",
    "LR = 1e-3\n",
    "\n",
    "def load_img(path_img, path_target, split):\n",
    "    #Obtain all the file paths for the input images and output targets. \n",
    "    images = sorted(glob(os.path.join(path_img, \"*\")))\n",
    "    target = sorted(glob(os.path.join(path_target, \"*\")))\n",
    "    #Randomly select 10% of the entire Dataset as Validation data.  \n",
    "    train_x, valid_x = train_test_split(images, test_size=int(split * len(images)), random_state=42)\n",
    "    train_y, valid_y = train_test_split(target, test_size=int(split * len(images)), random_state=42)\n",
    "    #Randomly select 10% of the entire Dataset as Testing data.\n",
    "    train_x, test_x = train_test_split(train_x, test_size=int(split * len(images)), random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=int(split * len(images)), random_state=42)\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    #Get path from file image.\n",
    "    path = path.decode()\n",
    "    #Read image from path using OpenCV.\n",
    "    img = cv2.imread(path)\n",
    "    #Resize image to 255x255.\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    #Normalize image.\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def read_target(path):\n",
    "    #Get path from file target.\n",
    "    path = path.decode()\n",
    "    #Read image from path as greyscale using OpenCV.\n",
    "    target = cv2.imread(path)\n",
    "    #Resize target to 255x255.\n",
    "    target = cv2.resize(target, (IMG_SIZE, IMG_SIZE))\n",
    "    #Define target at floating point.\n",
    "    target = target/255.0\n",
    "    return target\n",
    "\n",
    "def call_convert(img, msk):\n",
    "    def _convert(img, msk):\n",
    "        #Call data processing functions.\n",
    "        img = read_image(img)\n",
    "        msk = read_target(msk)\n",
    "        return img, msk\n",
    "        \n",
    "    img, msk = tf.numpy_function(_convert, [img, msk], [tf.float64, tf.float64])\n",
    "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    msk.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "\n",
    "    return img, msk\n",
    "\n",
    "def parse_dataset(img, msk, BATCH):\n",
    "    \n",
    "    data_set = tf.data.Dataset.from_tensor_slices((img, msk))\n",
    "    data_set = data_set.map(call_convert)\n",
    "    data_set = (data_set\n",
    "    .shuffle(BATCH*100)\n",
    "    .batch(BATCH)\n",
    "    .map(lambda i, j: (i, j), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE))\n",
    "    data_set = data_set.repeat()\n",
    "    return data_set\n",
    "\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_img(path_read_scene_and_flares, path_read_scenes, split=0.1)\n",
    "\n",
    "print(\"Training data: \", len(train_x))\n",
    "print(\"Validation data: \", len(valid_x))\n",
    "print(\"Testing data: \", len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f83161",
   "metadata": {},
   "source": [
    "**Quantization Aware Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21763f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\envs\\quant-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantize_layer (QuantizeLayer)  (None, 256, 256, 3)  3           input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "quant_inputs (QuantizeWrapperV2 (None, 256, 256, 16) 483         quantize_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_max_pooling2d_16 (Quantiz (None, 128, 128, 16) 1           quant_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_depthwise_conv2d (Quantiz (None, 128, 128, 16) 149         quant_max_pooling2d_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d (QuantizeWrapperV2 (None, 128, 128, 32) 611         quant_depthwise_conv2d[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_max_pooling2d_17 (Quantiz (None, 64, 64, 32)   1           quant_conv2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_depthwise_conv2d_1 (Quant (None, 64, 64, 32)   293         quant_max_pooling2d_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_1 (QuantizeWrapper (None, 64, 64, 48)   1683        quant_depthwise_conv2d_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "quant_max_pooling2d_18 (Quantiz (None, 32, 32, 48)   1           quant_conv2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_depthwise_conv2d_2 (Quant (None, 32, 32, 48)   437         quant_max_pooling2d_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrapper (None, 32, 32, 64)   3267        quant_depthwise_conv2d_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "quant_max_pooling2d_19 (Quantiz (None, 16, 16, 64)   1           quant_conv2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_transpose_18 (Quan (None, 32, 32, 64)   36933       quant_max_pooling2d_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_transpose_19 (Quan (None, 64, 64, 48)   27701       quant_conv2d_transpose_18[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_11 (QuantizeWrapperV2 (None, 64, 64, 48)   1           quant_conv2d_1[0][0]             \n",
      "                                                                 quant_conv2d_transpose_19[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_11 (QuantizeWr (None, 64, 64, 48)   3           quant_add_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_transpose_20 (Quan (None, 128, 128, 32) 13861       quant_activation_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_transpose_21 (Quan (None, 256, 256, 16) 4629        quant_conv2d_transpose_20[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_13 (QuantizeWrapperV2 (None, 256, 256, 16) 1           quant_inputs[0][0]               \n",
      "                                                                 quant_conv2d_transpose_21[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_13 (QuantizeWr (None, 256, 256, 16) 3           quant_add_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_6 (QuantizeWrapper (None, 256, 256, 16) 2355        quant_activation_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_7 (QuantizeWrapper (None, 256, 256, 3)  60          quant_conv2d_6[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 92,477\n",
      "Trainable params: 92,051\n",
      "Non-trainable params: 426\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "2119/2119 [==============================] - 842s 357ms/step - loss: 0.1897 - SSIMLoss: 0.1897 - val_loss: 0.1784 - val_SSIMLoss: 0.1784\n",
      "Epoch 2/5\n",
      "2119/2119 [==============================] - 433s 199ms/step - loss: 0.1780 - SSIMLoss: 0.1780 - val_loss: 0.1799 - val_SSIMLoss: 0.1798\n",
      "Epoch 3/5\n",
      "2119/2119 [==============================] - 446s 200ms/step - loss: 0.1830 - SSIMLoss: 0.1830 - val_loss: 0.1969 - val_SSIMLoss: 0.1968\n",
      "Epoch 4/5\n",
      "2119/2119 [==============================] - 364s 165ms/step - loss: 0.1835 - SSIMLoss: 0.1835 - val_loss: 0.1820 - val_SSIMLoss: 0.1820\n",
      "Epoch 5/5\n",
      "2119/2119 [==============================] - 329s 142ms/step - loss: 0.1813 - SSIMLoss: 0.1813 - val_loss: 0.1817 - val_SSIMLoss: 0.1818\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH = 12\n",
    "LR = 1e-4\n",
    "\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    SSIMLoss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "    return SSIMLoss\n",
    "\n",
    "test_model = tf.keras.models.load_model(\"/PATH/FlareNet_xxx.h5\", custom_objects={'SSIMLoss':SSIMLoss})\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "q_aware_model = quantize_model(test_model)\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "metrics = [SSIMLoss]\n",
    "q_aware_model.compile(loss=SSIMLoss, optimizer = opt, metrics=metrics)\n",
    "q_aware_model.summary()\n",
    "\n",
    "train_steps = len(train_x)//BATCH\n",
    "if len(train_x) % BATCH != 0: train_steps += 1\n",
    "valid_steps = len(valid_x)//BATCH\n",
    "if len(valid_x) % BATCH != 0: valid_steps += 1\n",
    "\n",
    "train_dataset = parse_dataset(train_x, train_y, BATCH)\n",
    "valid_dataset = parse_dataset(valid_x, valid_y, BATCH)\n",
    "\n",
    "#Quantization Aware Training:\n",
    "history = q_aware_model.fit(train_dataset, validation_data=valid_dataset, epochs=EPOCHS, steps_per_epoch=train_steps, validation_steps=valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08569047",
   "metadata": {},
   "source": [
    "#### Convert Model to TFLite format to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd537d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as inputs_layer_call_fn, inputs_layer_call_and_return_conditional_losses, conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, conv2d_1_layer_call_fn while saving (showing 5 of 50). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "#Convert to TFLite\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "path = \"/PATH/FlareNet_quant_xxx.tflite\"\n",
    "with open(path, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb8f49",
   "metadata": {},
   "source": [
    "**Evaluate Performance of Quantized Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d299947",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_10020\\2477215603.py:55: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  (score, diff) = structural_similarity(y, x, full=True, multichannel=True)\n",
      "C:\\Users\\David\\AppData\\Local\\Temp\\ipykernel_10020\\2477215603.py:60: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  (score, diff) = structural_similarity(y, y_pred, full=True, multichannel=True)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from scipy import stats\n",
    "mae_predict = 0\n",
    "mse_predict = 0\n",
    "mae_input = 0\n",
    "mse_input = 0\n",
    "ssmi_input_vs_original = 0\n",
    "ssmi_input_vs_predicted = 0\n",
    "\n",
    "num_test = len(test_x)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_target(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "for i, (x, y) in enumerate(zip(test_x[:num_test], test_y[:num_test])):\n",
    "\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "    \n",
    "    x = read_image(x)\n",
    "    y = read_target(y)\n",
    "    \n",
    "    test_image = np.expand_dims(x, axis=0).astype(np.float32)\n",
    "    interpreter.set_tensor(input_index, test_image)\n",
    "    #Run inference.\n",
    "    interpreter.invoke()\n",
    "    y_pred = interpreter.get_tensor(output_index)\n",
    "    y_pred = np.squeeze(y_pred)\n",
    "    \n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 20, 3))\n",
    "    all_images = [x, white_line, y, white_line, y_pred]\n",
    "\n",
    "    (score, diff) = structural_similarity(y, x, full=True, multichannel=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    ssmi_input_vs_original = ssmi_input_vs_original + score\n",
    "    #print(\"SSIM Original vs Input: {}\".format(score))\n",
    "\n",
    "    (score, diff) = structural_similarity(y, y_pred, full=True, multichannel=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    ssmi_input_vs_predicted = ssmi_input_vs_predicted + score\n",
    "    #print(\"SSIM Original vs Cleaned: {}\".format(score))\n",
    "    \n",
    "    mae_predict = mae_predict + np.mean(np.abs(y_pred - y))\n",
    "    mse_predict = mse_predict + np.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    mae_input = mae_input + np.mean(np.abs(x - y))\n",
    "    mse_input = mse_input + np.mean((x - y) ** 2)\n",
    "    \n",
    "    #image = np.concatenate(all_images, axis=1)\n",
    "    #fig = plt.figure(figsize=(12, 12))\n",
    "    #a = fig.add_subplot(1, 1, 1)\n",
    "    #imgplot = plt.imshow(image)\n",
    "\n",
    "print(\"Num Test:\", num_test)\n",
    "\n",
    "print(\"Average SSIM Input vs Original:\", ssmi_input_vs_original/num_test)\n",
    "print(\"Average SSIM Input vs Predicted:\", ssmi_input_vs_predicted/num_test)\n",
    "\n",
    "print(\"Average MAE Input vs Original:\", mae_input/num_test)\n",
    "print(\"Average MAE Input vs Predicted:\", mae_predict/num_test)\n",
    "\n",
    "print(\"Average MSE Input vs Original\", mse_input/num_test)\n",
    "print(\"Average MSE Input vs Predicted\", mse_predict/num_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4b045a",
   "metadata": {},
   "source": [
    "**Difference in Memory Consumption between Original and Quantized Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f56130c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\David\\AppData\\Local\\Temp\\tmp6hjicrri\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\David\\AppData\\Local\\Temp\\tmp6hjicrri\\assets\n",
      "C:\\Users\\David\\anaconda3\\envs\\quant-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float model in Mb: 0.3625679016113281\n",
      "Quantized model in Mb: 0.11336517333984375\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "# Create float TFLite model.\n",
    "float_converter = tf.lite.TFLiteConverter.from_keras_model(test_model)\n",
    "float_tflite_model = float_converter.convert()\n",
    "\n",
    "# Measure sizes of models.\n",
    "_, float_file = tempfile.mkstemp('.tflite')\n",
    "_, quant_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(quant_file, 'wb') as f:\n",
    "    f.write(quantized_tflite_model)\n",
    "\n",
    "with open(float_file, 'wb') as f:\n",
    "    f.write(float_tflite_model)\n",
    "\n",
    "print(\"Float model in Mb:\", os.path.getsize(float_file) / float(2**20))\n",
    "print(\"Quantized model in Mb:\", os.path.getsize(quant_file) / float(2**20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

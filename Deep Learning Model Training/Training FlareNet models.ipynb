{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaea05f5",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49471053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version:  2.6.0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, Activation, BatchNormalization, Lambda, concatenate, Add\n",
    "from tensorflow.keras.layers import UpSampling2D, SeparableConv2D, Input, Concatenate, MaxPooling2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from skimage.metrics import structural_similarity\n",
    "from tensorflow import keras\n",
    "#Check TensorFlow version:\n",
    "print(\"TensorFlow Version: \", tf.__version__)\n",
    "#Check if GPU is being used:\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc51426",
   "metadata": {},
   "source": [
    "#### Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3130375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:  25426\n",
      "Validation data:  3178\n",
      "Testing data:  3178\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 256\n",
    "path_read_scene_and_flares =  \"/PATH/Merged_images/\"\n",
    "path_read_scenes =  \"/PATH/Merged_images_saturated/\"\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH = 12\n",
    "LR = 1e-3\n",
    "\n",
    "def load_img(path_img, path_target, split):\n",
    "\n",
    "    #Obtain all the file paths for the input images and output targets. \n",
    "    images = sorted(glob(os.path.join(path_img, \"*\")))\n",
    "    target = sorted(glob(os.path.join(path_target, \"*\")))\n",
    "    #Randomly select 10% of the entire Dataset as Validation data.  \n",
    "    train_x, valid_x = train_test_split(images, test_size=int(split * len(images)), random_state=42)\n",
    "    train_y, valid_y = train_test_split(target, test_size=int(split * len(images)), random_state=42)\n",
    "    #Randomly select 10% of the entire Dataset as Testing data.\n",
    "    train_x, test_x = train_test_split(train_x, test_size=int(split * len(images)), random_state=42)\n",
    "    train_y, test_y = train_test_split(train_y, test_size=int(split * len(images)), random_state=42)\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image(path):\n",
    "    #Get path from file image.\n",
    "    path = path.decode()\n",
    "    #Read image from path using OpenCV.\n",
    "    img = cv2.imread(path)\n",
    "    #Resize image to 255x255.\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    #Normalize image.\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "def read_target(path):\n",
    "    #Get path from file target.\n",
    "    path = path.decode()\n",
    "    #Read image from path as greyscale using OpenCV.\n",
    "    target = cv2.imread(path)\n",
    "    #Resize target to 255x255.\n",
    "    target = cv2.resize(target, (IMG_SIZE, IMG_SIZE))\n",
    "    #Define target at floating point.\n",
    "    target = target/255.0\n",
    "    return target\n",
    "\n",
    "def call_convert(img, msk):\n",
    "    def _convert(img, msk):\n",
    "        #Call data processing functions.\n",
    "        img = read_image(img)\n",
    "        msk = read_target(msk)\n",
    "        return img, msk\n",
    "        \n",
    "    img, msk = tf.numpy_function(_convert, [img, msk], [tf.float64, tf.float64])\n",
    "    img.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "    msk.set_shape([IMG_SIZE, IMG_SIZE, 3])\n",
    "\n",
    "    return img, msk\n",
    "\n",
    "def parse_dataset(img, msk, BATCH):\n",
    "    \n",
    "    data_set = tf.data.Dataset.from_tensor_slices((img, msk))\n",
    "    data_set = data_set.map(call_convert)\n",
    "    data_set = (data_set\n",
    "    .shuffle(BATCH*100)\n",
    "    .batch(BATCH)\n",
    "    .map(lambda i, j: (i, j), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE))\n",
    "    data_set = data_set.repeat()\n",
    "    return data_set\n",
    "  \n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_img(path_read_scene_and_flares, path_read_scenes, split=0.1)\n",
    "\n",
    "print(\"Training data: \", len(train_x))\n",
    "print(\"Validation data: \", len(valid_x))\n",
    "print(\"Testing data: \", len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79acb9b",
   "metadata": {},
   "source": [
    "#### Define FlareNet-TL and FlareNet-simple architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498c7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlareNet_TL():\n",
    "    #Define input layer with size and name. \n",
    "    inputs = Input(shape=(256, 256, 3), name=\"input_image\")\n",
    "    #Load MobileNetV2:\n",
    "      #input layer is assigned to input of model.\n",
    "      #weights are pre-training on ImageNet\n",
    "      #do not include fully-connected layer at the top.\n",
    "      #alpha > 1 will proportionally increases the number of filters in each layer. \n",
    "    encoder = MobileNetV2(input_tensor=inputs, weights=\"imagenet\", include_top=False, alpha=0.35)\n",
    "    #Get MobileNetV2 specific layer output.\n",
    "    encoder_output = encoder.get_layer(\"block_13_expand_relu\").output\n",
    "    #Get MobileNetV2 specific layer output as skip connection.\n",
    "    x_skip = encoder.get_layer(\"block_6_expand_relu\").output\n",
    "    x = UpSampling2D((2, 2))(encoder_output)\n",
    "    x = Concatenate()([x, x_skip])\n",
    "    x = SeparableConv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = SeparableConv2D(64, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "     #Get MobileNetV2 specific layer output as skip connection.\n",
    "    x_skip = encoder.get_layer(\"block_3_expand_relu\").output\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Concatenate()([x, x_skip])\n",
    "    x = SeparableConv2D(48, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    #x = Conv2D(48, (3, 3), padding=\"same\")(x)\n",
    "    x = SeparableConv2D(48, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "     #Get MobileNetV2 specific layer output as skip connection.\n",
    "    x_skip = encoder.get_layer(\"block_1_expand_relu\").output\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Concatenate()([x, x_skip])\n",
    "    x = SeparableConv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = SeparableConv2D(32, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    #Get MobileNetV2 specific layer output as skip connection.\n",
    "    x_skip = encoder.get_layer(\"input_image\").output\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Concatenate()([x, x_skip])\n",
    "    x = SeparableConv2D(16, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = SeparableConv2D(16, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)   \n",
    "    #Last layer.\n",
    "    x = SeparableConv2D(3, (3, 3), padding=\"same\")(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "\n",
    "    FlareNet_TL = Model(inputs, x)\n",
    "\n",
    "    return FlareNet_TL\n",
    "\n",
    "model = FlareNet_TL()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bcc4be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FlareNet_simple():\n",
    "\n",
    "    inputs = Input((256, 256, 3))\n",
    "    x1_skip = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same', name=\"inputs\")(inputs)\n",
    "    x2 = MaxPooling2D((2, 2))(x1_skip)\n",
    "    x3 = SeparableConv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding=\"same\")(x2) \n",
    "    x4 = MaxPooling2D((2, 2))(x3)\n",
    "    x5_skip = SeparableConv2D(48, (3, 3), activation='relu', kernel_initializer='he_normal', padding=\"same\")(x4)\n",
    "    x6 = MaxPooling2D((2, 2))(x5_skip)\n",
    "    x7 = SeparableConv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding=\"same\")(x6)\n",
    "    x8 = MaxPooling2D((2, 2))(x7)\n",
    "    \n",
    "    x9 = Conv2DTranspose(64, (3, 3), activation='relu', padding=\"same\", kernel_initializer='he_normal', strides=2)(x8)\n",
    "    x10 = Conv2DTranspose(48, (3, 3), activation='relu', padding=\"same\", kernel_initializer='he_normal', strides=2)(x9)\n",
    "\n",
    "    x_skip1 = Add()([x5_skip, x10])\n",
    "    x_skip1 = Activation(\"relu\")(x_skip1) \n",
    "    x14 = Conv2DTranspose(32, (3, 3), activation='relu', padding=\"same\", kernel_initializer='he_normal', strides=2)(x_skip1)\n",
    "    x15 = Conv2DTranspose(16, (3, 3), activation='relu', padding=\"same\", kernel_initializer='he_normal', strides=2)(x14)\n",
    "\n",
    "    x_skip2 = Add()([x1_skip, x15])\n",
    "    x_skip2 = Activation(\"relu\")(x_skip2)   \n",
    "    outputs = Conv2D(3, (1, 1), activation='sigmoid')(x_skip2)\n",
    "\n",
    "    FlareNet_simple = Model(inputs, outputs)\n",
    "\n",
    "    return FlareNet_simple\n",
    "\n",
    "model = FlareNet_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac02756",
   "metadata": {},
   "source": [
    "#### Model Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read training and validation dataset.\n",
    "train_dataset = parse_dataset(train_x, train_y, BATCH)\n",
    "valid_dataset = parse_dataset(valid_x, valid_y, BATCH)\n",
    "\n",
    "#Define Loss function:\n",
    "def SSIMLoss(y_true, y_pred):\n",
    "    SSIMLoss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0))\n",
    "    return SSIMLoss\n",
    "\n",
    "#Define optimizer, metric and callback functions:\n",
    "opt = tf.keras.optimizers.Nadam(LR)\n",
    "metrics = [SSIMLoss]\n",
    "model.compile(loss=SSIMLoss, optimizer = opt, metrics=metrics)\n",
    "callbacks = [ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10), EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
    "\n",
    "train_steps = len(train_x)//BATCH\n",
    "if len(train_x) % BATCH != 0: train_steps += 1\n",
    "valid_steps = len(valid_x)//BATCH\n",
    "if len(valid_x) % BATCH != 0: valid_steps += 1\n",
    " \n",
    "history = model.fit(train_dataset, validation_data=valid_dataset, epochs=EPOCHS, steps_per_epoch=train_steps, validation_steps=valid_steps, callbacks=callbacks)\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5de508",
   "metadata": {},
   "source": [
    "#### Validate Model with Testing Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594db1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scipy import stats\n",
    "mae_predict = 0\n",
    "mse_predict = 0\n",
    "mae_input = 0\n",
    "mse_input = 0\n",
    "\n",
    "ssmi_input_vs_original = 0\n",
    "ssmi_input_vs_predicted = 0\n",
    "num_test = len(test_x)\n",
    "\n",
    "#Process data.\n",
    "def read_image(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "def read_target(path):\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.cvtColor(x, cv2.COLOR_BGR2RGB)\n",
    "    x = cv2.resize(x, (IMG_SIZE, IMG_SIZE))\n",
    "    x = x/255.0\n",
    "    return x\n",
    "\n",
    "for i, (x, y) in enumerate(zip(test_x[:num_test], test_y[:num_test])):\n",
    "    x = read_image(x)\n",
    "    y = read_target(y)\n",
    "    start = time.process_time()    \n",
    "    y_pred = model.predict(np.expand_dims(x, axis=0))[0]\n",
    "    print(time.process_time() - start)\n",
    "\n",
    "    #If required to print input image vs ground-truth vs prediction.\n",
    "    h, w, _ = x.shape\n",
    "    white_line = np.ones((h, 20, 3))\n",
    "    all_images = [x, white_line, y, white_line, y_pred]\n",
    "\n",
    "    ####### Calculate Metrics #######\n",
    "    (score, diff) = structural_similarity(y, x, full=True, multichannel=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    ssmi_input_vs_original = ssmi_input_vs_original + score\n",
    "\n",
    "    (score, diff) = structural_similarity(y, y_pred, full=True, multichannel=True)\n",
    "    diff = (diff * 255).astype(\"uint8\")\n",
    "    ssmi_input_vs_predicted = ssmi_input_vs_predicted + score\n",
    "\n",
    "    mae_predict = mae_predict + np.mean(np.abs(y_pred - y))\n",
    "    mse_predict = mse_predict + np.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    mae_input = mae_input + np.mean(np.abs(x - y))\n",
    "    mse_input = mse_input + np.mean((x - y) ** 2)\n",
    "\n",
    "    #image = np.concatenate(all_images, axis=1)\n",
    "    #fig = plt.figure(figsize=(12, 12))\n",
    "    #a = fig.add_subplot(1, 1, 1)\n",
    "    #imgplot = plt.imshow(image)\n",
    "\n",
    "print(\"Num Test:\", num_test)\n",
    "\n",
    "print(\"Average SSIM Input vs Original:\", ssmi_input_vs_original/num_test)\n",
    "print(\"Average SSIM Input vs Predicted:\", ssmi_input_vs_predicted/num_test)\n",
    "\n",
    "print(\"Average MAE Input vs Original:\", mae_input/num_test)\n",
    "print(\"Average MAE Input vs Predicted:\", mae_predict/num_test)\n",
    "\n",
    "print(\"Average MSE Input vs Original\", mse_input/num_test)\n",
    "print(\"Average MSE Input vs Predicted\", mse_predict/num_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "875cb5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"/PATH/FlareNet_XXX.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
